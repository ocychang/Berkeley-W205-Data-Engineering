{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Take in raw data from kafka to spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "assessments_kafka = spark \\\n",
    "  .read \\\n",
    "  .format(\"kafka\") \\\n",
    "  .option(\"kafka.bootstrap.servers\", \"kafka:29092\") \\\n",
    "  .option(\"subscribe\", \"assessments\") \\\n",
    "  .option(\"startingOffsets\", \"earliest\") \\\n",
    "  .option(\"endingOffsets\", \"latest\") \\\n",
    "  .load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[key: binary, value: binary, topic: string, partition: int, offset: bigint, timestamp: timestamp, timestampType: int]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "assessments_kafka.cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Show raw data schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- key: binary (nullable = true)\n",
      " |-- value: binary (nullable = true)\n",
      " |-- topic: string (nullable = true)\n",
      " |-- partition: integer (nullable = true)\n",
      " |-- offset: long (nullable = true)\n",
      " |-- timestamp: timestamp (nullable = true)\n",
      " |-- timestampType: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "assessments_kafka.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check raw data type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pyspark.sql.dataframe.DataFrame"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(assessments_kafka)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check topic and value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+--------------------+-----------+---------+------+--------------------+-------------+\n",
      "| key|               value|      topic|partition|offset|           timestamp|timestampType|\n",
      "+----+--------------------+-----------+---------+------+--------------------+-------------+\n",
      "|null|[7B 22 6B 65 65 6...|assessments|        0|     0|1969-12-31 23:59:...|            0|\n",
      "|null|[7B 22 6B 65 65 6...|assessments|        0|     1|1969-12-31 23:59:...|            0|\n",
      "|null|[7B 22 6B 65 65 6...|assessments|        0|     2|1969-12-31 23:59:...|            0|\n",
      "|null|[7B 22 6B 65 65 6...|assessments|        0|     3|1969-12-31 23:59:...|            0|\n",
      "|null|[7B 22 6B 65 65 6...|assessments|        0|     4|1969-12-31 23:59:...|            0|\n",
      "|null|[7B 22 6B 65 65 6...|assessments|        0|     5|1969-12-31 23:59:...|            0|\n",
      "|null|[7B 22 6B 65 65 6...|assessments|        0|     6|1969-12-31 23:59:...|            0|\n",
      "|null|[7B 22 6B 65 65 6...|assessments|        0|     7|1969-12-31 23:59:...|            0|\n",
      "|null|[7B 22 6B 65 65 6...|assessments|        0|     8|1969-12-31 23:59:...|            0|\n",
      "|null|[7B 22 6B 65 65 6...|assessments|        0|     9|1969-12-31 23:59:...|            0|\n",
      "|null|[7B 22 6B 65 65 6...|assessments|        0|    10|1969-12-31 23:59:...|            0|\n",
      "|null|[7B 22 6B 65 65 6...|assessments|        0|    11|1969-12-31 23:59:...|            0|\n",
      "|null|[7B 22 6B 65 65 6...|assessments|        0|    12|1969-12-31 23:59:...|            0|\n",
      "|null|[7B 22 6B 65 65 6...|assessments|        0|    13|1969-12-31 23:59:...|            0|\n",
      "|null|[7B 22 6B 65 65 6...|assessments|        0|    14|1969-12-31 23:59:...|            0|\n",
      "|null|[7B 22 6B 65 65 6...|assessments|        0|    15|1969-12-31 23:59:...|            0|\n",
      "|null|[7B 22 6B 65 65 6...|assessments|        0|    16|1969-12-31 23:59:...|            0|\n",
      "|null|[7B 22 6B 65 65 6...|assessments|        0|    17|1969-12-31 23:59:...|            0|\n",
      "|null|[7B 22 6B 65 65 6...|assessments|        0|    18|1969-12-31 23:59:...|            0|\n",
      "|null|[7B 22 6B 65 65 6...|assessments|        0|    19|1969-12-31 23:59:...|            0|\n",
      "+----+--------------------+-----------+---------+------+--------------------+-------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "assessments_kafka.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import pyspark libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import sys \n",
    "import json\n",
    "from pyspark.sql import Row\n",
    "from pyspark.sql.functions import from_json, col, lit, countDistinct, avg, col\n",
    "from pyspark.sql.types import StructType, StructField, StringType, BooleanType, LongType\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cast values as strings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "assessments_true = assessments_kafka.select(assessments_kafka.value.cast('string'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract Json data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "assessments_exr = spark.read.json(assessments_true.rdd.map(lambda x: x.value))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-------------+--------------------+-----------------+--------------------+-----------------+------------+--------------------+--------------------+--------------------+\n",
      "|        base_exam_id|certification|           exam_name|  keen_created_at|             keen_id|   keen_timestamp|max_attempts|           sequences|          started_at|        user_exam_id|\n",
      "+--------------------+-------------+--------------------+-----------------+--------------------+-----------------+------------+--------------------+--------------------+--------------------+\n",
      "|37f0a30a-7464-11e...|        false|Normal Forms and ...|1516717442.735266|5a6745820eb8ab000...|1516717442.735266|         1.0|[1,[false,2,1,1,4...|2018-01-23T14:23:...|6d4089e4-bde5-4a2...|\n",
      "+--------------------+-------------+--------------------+-----------------+--------------------+-----------------+------------+--------------------+--------------------+--------------------+\n",
      "only showing top 1 row\n",
      "\n"
     ]
    }
   ],
   "source": [
    "assessments_exr.show(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The structure from the previous show() function is not easy to read. Contruct/register a table for better schema structure to view."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "assessments_exr.registerTempTable('assessments_exr')\n",
    "df_asmt = assessments_exr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- base_exam_id: string (nullable = true)\n",
      " |-- certification: string (nullable = true)\n",
      " |-- exam_name: string (nullable = true)\n",
      " |-- keen_created_at: string (nullable = true)\n",
      " |-- keen_id: string (nullable = true)\n",
      " |-- keen_timestamp: string (nullable = true)\n",
      " |-- max_attempts: string (nullable = true)\n",
      " |-- sequences: struct (nullable = true)\n",
      " |    |-- attempt: long (nullable = true)\n",
      " |    |-- counts: struct (nullable = true)\n",
      " |    |    |-- all_correct: boolean (nullable = true)\n",
      " |    |    |-- correct: long (nullable = true)\n",
      " |    |    |-- incomplete: long (nullable = true)\n",
      " |    |    |-- incorrect: long (nullable = true)\n",
      " |    |    |-- submitted: long (nullable = true)\n",
      " |    |    |-- total: long (nullable = true)\n",
      " |    |    |-- unanswered: long (nullable = true)\n",
      " |    |-- id: string (nullable = true)\n",
      " |    |-- questions: array (nullable = true)\n",
      " |    |    |-- element: struct (containsNull = true)\n",
      " |    |    |    |-- id: string (nullable = true)\n",
      " |    |    |    |-- options: array (nullable = true)\n",
      " |    |    |    |    |-- element: struct (containsNull = true)\n",
      " |    |    |    |    |    |-- at: string (nullable = true)\n",
      " |    |    |    |    |    |-- checked: boolean (nullable = true)\n",
      " |    |    |    |    |    |-- correct: boolean (nullable = true)\n",
      " |    |    |    |    |    |-- id: string (nullable = true)\n",
      " |    |    |    |    |    |-- submitted: long (nullable = true)\n",
      " |    |    |    |-- user_correct: boolean (nullable = true)\n",
      " |    |    |    |-- user_incomplete: boolean (nullable = true)\n",
      " |    |    |    |-- user_result: string (nullable = true)\n",
      " |    |    |    |-- user_submitted: boolean (nullable = true)\n",
      " |-- started_at: string (nullable = true)\n",
      " |-- user_exam_id: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_asmt.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Now query the nested json data to answer some basic questions:\n",
    "- How many assesstments are in the dataset?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3280"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_asmt.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "- How many people took Learning Git?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+\n",
      "|           exam_name|\n",
      "+--------------------+\n",
      "|Normal Forms and ...|\n",
      "|Normal Forms and ...|\n",
      "|The Principles of...|\n",
      "|The Principles of...|\n",
      "|Introduction to B...|\n",
      "|        Learning Git|\n",
      "|Git Fundamentals ...|\n",
      "|Introduction to P...|\n",
      "|Intermediate Pyth...|\n",
      "|Introduction to P...|\n",
      "+--------------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# check if learning git is in exam name\n",
    "df_asmt.select(\"exam_name\").show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "394"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# filter and count learning git frequency\n",
    "\n",
    "df_asmt.filter(df_asmt[\"exam_name\"] == \"Learning Git\").count()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "- What is the least common course taken? And the most common?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------------------------------------------------+-----+\n",
      "|exam_name                                                     |count|\n",
      "+--------------------------------------------------------------+-----+\n",
      "|Learning Git                                                  |394  |\n",
      "|Introduction to Python                                        |162  |\n",
      "|Introduction to Java 8                                        |158  |\n",
      "|Intermediate Python Programming                               |158  |\n",
      "|Learning to Program with R                                    |128  |\n",
      "|Introduction to Machine Learning                              |119  |\n",
      "|Software Architecture Fundamentals Understanding the Basics   |109  |\n",
      "|Beginning C# Programming                                      |95   |\n",
      "|Learning Eclipse                                              |85   |\n",
      "|Learning Apache Maven                                         |80   |\n",
      "|Beginning Programming with JavaScript                         |79   |\n",
      "|Mastering Git                                                 |77   |\n",
      "|Introduction to Big Data                                      |75   |\n",
      "|Advanced Machine Learning                                     |67   |\n",
      "|Learning Linux System Administration                          |59   |\n",
      "|JavaScript: The Good Parts Master Class with Douglas Crockford|58   |\n",
      "|Learning SQL                                                  |57   |\n",
      "|Practical Java Programming                                    |53   |\n",
      "|HTML5 The Basics                                              |52   |\n",
      "|Python Epiphanies                                             |51   |\n",
      "+--------------------------------------------------------------+-----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_asmt.groupBy(\"exam_name\").count().sort(col(\"count\").desc()).show(truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "- Which exam has the highest unanswered rate "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+\n",
      "|           exam_name|      per_unanswered|\n",
      "+--------------------+--------------------+\n",
      "|       View Updating|                0.25|\n",
      "|Learning Spring P...|                0.25|\n",
      "|Native Web Apps f...|                0.25|\n",
      "|Mastering Advance...| 0.17647058823529413|\n",
      "|Networking for Pe...| 0.13333333333333333|\n",
      "|          Great Bash| 0.12857142857142856|\n",
      "|Hibernate and JPA...|               0.125|\n",
      "|Learning C# Best ...|                0.12|\n",
      "|Amazon Web Servic...|  0.1111111111111111|\n",
      "|Design Patterns i...| 0.10666666666666667|\n",
      "|              TCP/IP| 0.08571428571428572|\n",
      "|Cloud Computing W...| 0.07352941176470588|\n",
      "|Software Architec...| 0.07339449541284404|\n",
      "|Amazon Web Servic...| 0.06818181818181818|\n",
      "|Learning C# Desig...| 0.06521739130434782|\n",
      "|Learning Apache C...|              0.0625|\n",
      "|        Learning Git| 0.06040609137055838|\n",
      "|Python Data Struc...|  0.0603448275862069|\n",
      "|JavaScript: The G...|  0.0603448275862069|\n",
      "|Learning iPython ...|0.058823529411764705|\n",
      "+--------------------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# try using spark.sql to calculate percentages\n",
    "\n",
    "spark.sql(\"select exam_name, \\\n",
    "            sum(sequences.counts.unanswered)/sum(sequences.counts.total) \\\n",
    "            as per_unanswered \\\n",
    "            from assessments_exr \\\n",
    "            group by exam_name \\\n",
    "            order by per_unanswered desc\"\\\n",
    "          ).show(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Which exam has the highest imcomplete rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-------------------+\n",
      "|           exam_name|         per_incomp|\n",
      "+--------------------+-------------------+\n",
      "|       View Updating|                0.5|\n",
      "|Building Web Serv...| 0.4166666666666667|\n",
      "|  Learning Java EE 7|                0.4|\n",
      "|Web & Native Work...|              0.375|\n",
      "|I'm a Software Ar...|0.36666666666666664|\n",
      "|Cloud Computing W...|0.35294117647058826|\n",
      "|Arduino Prototypi...| 0.3333333333333333|\n",
      "| Mastering Web Views| 0.3333333333333333|\n",
      "|Introduction to A...|0.30952380952380953|\n",
      "|Amazon Web Servic...| 0.3055555555555556|\n",
      "|Modeling for Soft...|               0.25|\n",
      "|Normal Forms and ...|               0.25|\n",
      "|Introduction to D...|0.23920265780730898|\n",
      "|The Principles of...|0.22727272727272727|\n",
      "|Architectural Con...|               0.22|\n",
      "|Design Patterns i...|0.21333333333333335|\n",
      "|An Introduction t...|                0.2|\n",
      "|Client-Side Data ...|                0.2|\n",
      "|SQL: Beyond the B...|0.18181818181818182|\n",
      "|Event-Driven Micr...|               0.18|\n",
      "+--------------------+-------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"select exam_name, \\\n",
    "            sum(sequences.counts.incomplete)/sum(sequences.counts.total) \\\n",
    "            as per_incomp \\\n",
    "            from assessments_exr \\\n",
    "            group by exam_name \\\n",
    "            order by per_incomp desc\"\\\n",
    "          ).show(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "- Which exams are the most difficult (lowest correct rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-------------------+\n",
      "|           exam_name|           per_cort|\n",
      "+--------------------+-------------------+\n",
      "|Example Exam For ...|               null|\n",
      "|Client-Side Data ...|                0.2|\n",
      "|Native Web Apps f...|               0.25|\n",
      "|       View Updating|               0.25|\n",
      "|Arduino Prototypi...| 0.3333333333333333|\n",
      "|Mastering Advance...| 0.3602941176470588|\n",
      "|           Nullology|              0.375|\n",
      "|Building Web Serv...| 0.4166666666666667|\n",
      "|Web & Native Work...| 0.4166666666666667|\n",
      "| Mastering Web Views| 0.4166666666666667|\n",
      "|Cloud Computing W...| 0.4264705882352941|\n",
      "|         Offline Web| 0.4358974358974359|\n",
      "|Learning C# Best ...|0.46285714285714286|\n",
      "|Design Patterns i...| 0.4666666666666667|\n",
      "|Software Architec...| 0.4793577981651376|\n",
      "|  Learning Java EE 7|               0.48|\n",
      "|Data Visualizatio...|0.49193548387096775|\n",
      "|Using Web Components|                0.5|\n",
      "|Amazon Web Servic...|                0.5|\n",
      "|Learning Data Str...|                0.5|\n",
      "+--------------------+-------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"select exam_name, \\\n",
    "            sum(sequences.counts.correct)/sum(sequences.counts.total) \\\n",
    "            as per_cort \\\n",
    "            from assessments_exr \\\n",
    "            group by exam_name \\\n",
    "            order by per_cort asc\"\\\n",
    "          ).show(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "- Which courses have the higherest average attempts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-----------+\n",
      "|           exam_name|avg_max_atp|\n",
      "+--------------------+-----------+\n",
      "|Learning Spring P...|        1.0|\n",
      "|Networking for Pe...|        1.0|\n",
      "|Learning iPython ...|        1.0|\n",
      "|Introduction to P...|        1.0|\n",
      "|Introduction to A...|        1.0|\n",
      "|Learning Data Mod...|        1.0|\n",
      "|Introduction to J...|        1.0|\n",
      "|Learning Apache H...|        1.0|\n",
      "|Learning C# Best ...|        1.0|\n",
      "|Mastering Python ...|        1.0|\n",
      "|Introduction to B...|        1.0|\n",
      "|       View Updating|        1.0|\n",
      "|A Practical Intro...|        1.0|\n",
      "|Introduction to A...|        1.0|\n",
      "|Intermediate C# P...|        1.0|\n",
      "|I'm a Software Ar...|        1.0|\n",
      "|JavaScript Templa...|        1.0|\n",
      "|        Learning DNS|        1.0|\n",
      "|Starting a Grails...|        1.0|\n",
      "|Being a Better In...|        1.0|\n",
      "+--------------------+-----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"select exam_name, \\\n",
    "            avg(max_attempts)\\\n",
    "            as avg_max_atp \\\n",
    "            from assessments_exr \\\n",
    "            group by exam_name \\\n",
    "            order by avg_max_atp desc\"\\\n",
    "          ).show(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Which questions are the most difficult"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+\n",
      "|                q_id|        user_correct|\n",
      "+--------------------+--------------------+\n",
      "|[7a2ed6d3-f492-49...|[false, false, tr...|\n",
      "|[95194331-ac43-45...|[true, false, fal...|\n",
      "|[b9ff2e88-cf9d-4b...|[false, true, tru...|\n",
      "|[1f7c5def-904b-48...|[true, false, tru...|\n",
      "|[620c924f-6bd8-11...|[false, true, tru...|\n",
      "+--------------------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# show data structure and content\n",
    "temp = spark.sql(\"select sequences.questions.id as q_id, \\\n",
    "            sequences.questions.user_correct \\\n",
    "            from assessments_exr\" \\\n",
    "          ).show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One could unwrap the user_correct col and count the ture vs. false ratio and determien the most difficult questions. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Who take more than one courses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+------------+\n",
      "|        user_exam_id|course_count|\n",
      "+--------------------+------------+\n",
      "|6132da16-2c0c-436...|           3|\n",
      "|cdc5859d-b332-4fb...|           3|\n",
      "|66d91177-c436-4ee...|           3|\n",
      "|028ad26f-a89f-4a6...|           3|\n",
      "|fa23b287-0d0a-468...|           3|\n",
      "|b7ac6d15-97e1-4e9...|           3|\n",
      "|a45b5ee6-a4ed-4b1...|           3|\n",
      "|d4ab4aeb-1368-486...|           3|\n",
      "|bd96cfbe-1532-4ba...|           3|\n",
      "|a7e6fc04-245f-4e3...|           3|\n",
      "+--------------------+------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"select user_exam_id, \\\n",
    "            count(exam_name) as course_count \\\n",
    "            from assessments_exr \\\n",
    "            group by user_exam_id \\\n",
    "            order by course_count desc\" \\\n",
    "          ).show(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looks like some users took as much as 3 courses."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save into HDFS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_asmt.write.parquet(\"/tmp/assessments_hdfs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# ran this in terminal: \n",
    "docker-compose exec cloudera hadoop fs -ls /tmp/\n",
    "\n",
    "# and get: \n",
    "#drwxr-xr-x   - root   supergroup          0 2021-03-08 05:43 /tmp/assessments_hdfs\n",
    "#drwxrwxrwt   - mapred mapred              0 2018-02-06 18:27 /tmp/hadoop-yarn\n",
    "#drwx-wx-wx   - root   supergroup          0 2021-03-08 05:40 /tmp/hive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-------------+--------------------+------------------+--------------------+------------------+------------+--------------------+--------------------+--------------------+\n",
      "|        base_exam_id|certification|           exam_name|   keen_created_at|             keen_id|    keen_timestamp|max_attempts|           sequences|          started_at|        user_exam_id|\n",
      "+--------------------+-------------+--------------------+------------------+--------------------+------------------+------------+--------------------+--------------------+--------------------+\n",
      "|37f0a30a-7464-11e...|        false|Normal Forms and ...| 1516717442.735266|5a6745820eb8ab000...| 1516717442.735266|         1.0|[1,[false,2,1,1,4...|2018-01-23T14:23:...|6d4089e4-bde5-4a2...|\n",
      "|37f0a30a-7464-11e...|        false|Normal Forms and ...| 1516717377.639827|5a674541ab6b0a000...| 1516717377.639827|         1.0|[1,[false,1,2,1,4...|2018-01-23T14:21:...|2fec1534-b41f-441...|\n",
      "|4beeac16-bb83-4d5...|        false|The Principles of...| 1516738973.653394|5a67999d3ed3e3000...| 1516738973.653394|         1.0|[1,[false,3,0,1,4...|2018-01-23T20:22:...|8edbc8a8-4d26-429...|\n",
      "|4beeac16-bb83-4d5...|        false|The Principles of...|1516738921.1137421|5a6799694fc7c7000...|1516738921.1137421|         1.0|[1,[false,2,2,0,4...|2018-01-23T20:21:...|c0ee680e-8892-4e6...|\n",
      "|6442707e-7488-11e...|        false|Introduction to B...| 1516737000.212122|5a6791e824fccd000...| 1516737000.212122|         1.0|[1,[false,3,0,1,4...|2018-01-23T19:48:...|e4525b79-7904-405...|\n",
      "|8b4488de-43a5-4ff...|        false|        Learning Git| 1516740790.309757|5a67a0b6852c2a000...| 1516740790.309757|         1.0|[1,[true,5,0,0,5,...|2018-01-23T20:51:...|3186dafa-7acf-47e...|\n",
      "|e1f07fac-5566-4fd...|        false|Git Fundamentals ...|1516746279.3801291|5a67b627cc80e6000...|1516746279.3801291|         1.0|[1,[true,1,0,0,1,...|2018-01-23T22:24:...|48d88326-36a3-4cb...|\n",
      "|7e2e0b53-a7ba-458...|        false|Introduction to P...| 1516743820.305464|5a67ac8cb0a5f4000...| 1516743820.305464|         1.0|[1,[true,5,0,0,5,...|2018-01-23T21:43:...|bb152d6b-cada-41e...|\n",
      "|1a233da8-e6e5-48a...|        false|Intermediate Pyth...|  1516743098.56811|5a67a9ba060087000...|  1516743098.56811|         1.0|[1,[true,4,0,0,4,...|2018-01-23T21:31:...|70073d6f-ced5-4d0...|\n",
      "|7e2e0b53-a7ba-458...|        false|Introduction to P...| 1516743764.813107|5a67ac54411aed000...| 1516743764.813107|         1.0|[1,[false,0,1,0,1...|2018-01-23T21:42:...|9eb6d4d6-fd1f-4f3...|\n",
      "+--------------------+-------------+--------------------+------------------+--------------------+------------------+------------+--------------------+--------------------+--------------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# test read\n",
    "sqlContext.read.parquet(\"/tmp/assessments_hdfs\").show(10) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
